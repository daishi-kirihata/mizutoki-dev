{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然言語処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MeCabの準備\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 導入手順（Windows 10）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [MeCab](https://github.com/ikegami-yukino/mecab/releases/tag/v0.996)をダウンロード・インストールする。\n",
    "<br />※公式の32bit版ではなく、有志がビルドした64bit版を使用する。\n",
    "1. システムのプロパティから環境変数の編集で\"Path\"を選択し、以下のパスを追加する。\n",
    " * `（MeCabインストール先）\\bin`\n",
    "1. （仮想環境上の）コマンドプロンプトを起動し、以下のコマンドを実行し、インストールする。\n",
    " * `pip install ipykernel` \\# 最初からAnaconda環境に含まれている\n",
    " * `pip install mecab-python-windows`\n",
    "1. インストールが完了したら、`（MeCabインストールパス）\\bin`にあるファイル`libmecab.dll`を以下のフォルダにコピー & ペーストする。\n",
    " * `（Anacondaインストール先）\\Lib\\site-packages`\n",
    "1. 以上でpythonからMeCabが実行可能になる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import MeCab\n",
    "import re\n",
    "\n",
    "# テキストの設定\n",
    "text = 'すもももももももものうち。'\n",
    "\n",
    "# 形態素解析\n",
    "header = '表層形\\t品詞,品詞細分類1,品詞細分類2,品詞細分類3,活用型,活用形,原形,読み,発音'\n",
    "parse = MeCab.Tagger().parse(text)\n",
    "\n",
    "lines = list()\n",
    "lines.append(header)\n",
    "lines.extend(parse.split('\\n'))\n",
    "items = [re.split('[\\t,]', line) for line in lines if len(re.split('[\\t,]', line)) == 10]\n",
    "\n",
    "# 結果を表示\n",
    "for item in items:\n",
    "    print(item)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [PythonとMeCabで形態素解析(on Windows) - Qiita](https://qiita.com/menon/items/f041b7c46543f38f78f7)\n",
    "* [PythonでMeCabを使ってみる(Windows10 64bit) - Qiita](https://qiita.com/wanko5296/items/eeb7865ee71a7b9f1a3a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ユーザ辞書（csv）の作成・コンパイル\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csvファイルを作成しました。csvファイル名: user_mecab\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>表層形</th>\n",
       "      <th>左文脈ID</th>\n",
       "      <th>右文脈ID</th>\n",
       "      <th>コスト</th>\n",
       "      <th>品詞</th>\n",
       "      <th>品詞細分類1</th>\n",
       "      <th>品詞細分類2</th>\n",
       "      <th>品詞細分類3</th>\n",
       "      <th>活用形</th>\n",
       "      <th>活用型</th>\n",
       "      <th>原形</th>\n",
       "      <th>読み</th>\n",
       "      <th>発音</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>言葉</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>名詞</td>\n",
       "      <td>一般</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>言葉</td>\n",
       "      <td>コトバ</td>\n",
       "      <td>コトバ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>すもももももももものうち</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>名詞</td>\n",
       "      <td>一般</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>すもももももももものうち</td>\n",
       "      <td>スモモモモモモモモノウチ</td>\n",
       "      <td>スモモモモモモモモノウチ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            表層形  左文脈ID  右文脈ID  コスト  品詞 品詞細分類1 品詞細分類2 品詞細分類3 活用形 活用型  \\\n",
       "0            言葉      1      1    1  名詞     一般      *      *   *   *   \n",
       "1  すもももももももものうち      1      1    1  名詞     一般      *      *   *   *   \n",
       "\n",
       "             原形            読み            発音  \n",
       "0            言葉           コトバ           コトバ  \n",
       "1  すもももももももものうち  スモモモモモモモモノウチ  スモモモモモモモモノウチ  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "def MeCabDictionary(MeCabDictionaryList):\n",
    "    '''\n",
    "    outline : \n",
    "    input : list([string, string, string, string, string, string], )\n",
    "    output : pandas.dataframe\n",
    "    '''\n",
    "    columns = ['表層形', '左文脈ID', '右文脈ID', 'コスト', '品詞', '品詞細分類1', '品詞細分類2', '品詞細分類3', '活用形', '活用型', '原形', '読み', '発音']\n",
    "    data = list()\n",
    "    for item in MeCabDictionaryList:\n",
    "        data.append([item[0], 1, 1, 1, item[1], item[2], '*', '*', '*', '*', item[3], item[4], item[5]])\n",
    "    return pandas.DataFrame(data=data, columns=columns)\n",
    "    \n",
    "registerWords = [\n",
    "    ['言葉', '名詞', '一般', '言葉', 'コトバ', 'コトバ'],\n",
    "    ['すもももももももものうち', '名詞', '一般', 'すもももももももものうち', 'スモモモモモモモモノウチ', 'スモモモモモモモモノウチ']\n",
    "]\n",
    "\n",
    "fileName = 'user_mecab'\n",
    "csvDataFrame = MeCabDictionary(registerWords)\n",
    "csvDataFrame.to_csv('csv\\{0}.csv'.format(fileName), header=False, index=False)\n",
    "\n",
    "print('csvファイルを作成しました。csvファイル名: {0}'.format(fileName)) \n",
    "csvDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading user_mecab.csv ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "\n",
      "done!\n",
      "\n",
      "        1 個のファイルを移動しました。\n",
      "\n",
      "ユーザ辞書を作成しました。\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "mecabPath = r'c:\\Program Files\\MeCab'\n",
    "currentPath = r'c:\\Users\\hajime\\ipynb'\n",
    "fileName = 'user_mecab'\n",
    "commands = list()\n",
    "commands.append(r'\"{0}\\bin\\mecab-dict-index.exe\" -d \"{0}\\dic\\ipadic\" -u {1}.dic -f utf-8 -t utf-8 {1}.csv'.format(mecabPath, fileName))\n",
    "commands.append(r'move {1}.dic {0}\\dic'.format(currentPath, fileName))\n",
    "for command in commands:\n",
    "    proc = subprocess.run(command, cwd=r'{0}\\csv'.format(currentPath), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=3)\n",
    "    print(proc.stdout.decode('cp932'))\n",
    "    \n",
    "print('ユーザ辞書を作成しました。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ユーザ辞書の指定\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['表層形', '品詞', '品詞細分類1', '品詞細分類2', '品詞細分類3', '活用型', '活用形', '原形', '読み', '発音'], ['すもももももももものうち', '名詞', '一般', '*', '*', '*', '*', 'すもももももももものうち', 'スモモモモモモモモノウチ', 'スモモモモモモモモノウチ']]\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "import re\n",
    "\n",
    "def ParsesWithUserDic(text):\n",
    "    '''\n",
    "    outline: \n",
    "    \n",
    "    @param: \n",
    "    @type: \n",
    "    @rtype: \n",
    "    '''\n",
    "    userDic = 'user_mecab'\n",
    "    \n",
    "    # 形態素解析\n",
    "    header = '表層形\\t品詞,品詞細分類1,品詞細分類2,品詞細分類3,活用型,活用形,原形,読み,発音'\n",
    "    parse = MeCab.Tagger('-u dic/{0}.dic'.format(fileName)).parse(text)\n",
    "    \n",
    "    lines = list()\n",
    "    lines.append(header)\n",
    "    lines.extend(parse.split('\\n'))\n",
    "    items = [re.split('[\\t,]', line) for line in lines if len(re.split('[\\t,]', line)) == 10]\n",
    "    \n",
    "    # 結果を出力する\n",
    "    return items\n",
    "\n",
    "print(ParsesWithUserDic('すもももももももものうち'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MeCabの実行\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function Parses in module __main__:\n",
      "\n",
      "Parses(text)\n",
      "    outline: 形態素データを取得する\n",
      "    \n",
      "    @param text: C(str)\n",
      "    @type text: C(list)\n",
      "    @rtype: C(list)\n",
      "\n",
      "[['表層形', '品詞', '品詞細分類1', '品詞細分類2', '品詞細分類3', '活用型', '活用形', '原形', '読み', '発音'], ['すもも', '名詞', '一般', '*', '*', '*', '*', 'すもも', 'スモモ', 'スモモ'], ['も', '助詞', '係助詞', '*', '*', '*', '*', 'も', 'モ', 'モ'], ['もも', '名詞', '一般', '*', '*', '*', '*', 'もも', 'モモ', 'モモ'], ['も', '助詞', '係助詞', '*', '*', '*', '*', 'も', 'モ', 'モ'], ['もも', '名詞', '一般', '*', '*', '*', '*', 'もも', 'モモ', 'モモ'], ['の', '助詞', '連体化', '*', '*', '*', '*', 'の', 'ノ', 'ノ'], ['うち', '名詞', '非自立', '副詞可能', '*', '*', '*', 'うち', 'ウチ', 'ウチ']]\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "import re\n",
    "\n",
    "def Parses(text):\n",
    "    '''\n",
    "    outline: 形態素データを取得する\n",
    "    \n",
    "    @param text: C(str)\n",
    "    @type text: C(list)\n",
    "    @rtype: C(list)\n",
    "    '''\n",
    "    # 形態素解析\n",
    "    header = '表層形\\t品詞,品詞細分類1,品詞細分類2,品詞細分類3,活用型,活用形,原形,読み,発音'\n",
    "    parse = MeCab.Tagger().parse(text)\n",
    "    \n",
    "    lines = list()\n",
    "    lines.append(header)\n",
    "    lines.extend(parse.split('\\n'))\n",
    "    items = [re.split('[\\t,]', line) for line in lines if len(re.split('[\\t,]', line)) == 10]\n",
    "    \n",
    "    # 結果を出力する\n",
    "    return items\n",
    "\n",
    "help(Parses)\n",
    "print(Parses('すもももももももものうち'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文の分割\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetParsesPart(text, index):\n",
    "    '''\n",
    "    outline : \n",
    "    input : text, index\n",
    "    output : list(string)\n",
    "    '''\n",
    "    parts = [wordParse[index] for wordParse in Parses(text)]\n",
    "    del parts[0] # header情報の削除\n",
    "    return parts\n",
    "\n",
    "def SplitWord(text):\n",
    "    '''\n",
    "    outline : \n",
    "    input : text\n",
    "    output : list(string)\n",
    "    '''\n",
    "    return GetParsesPart(text, 0)\n",
    "\n",
    "def SplitClass(text):\n",
    "    '''\n",
    "    outline : \n",
    "    input : text\n",
    "    output : list(string)\n",
    "    '''\n",
    "    return GetParsesPart(text, 1)\n",
    "    \n",
    "print(', '.join(SplitWord('すもももももももものうち。')))\n",
    "print(', '.join(SplitClass('すもももももももものうち。')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTMLテキストの処理\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib import parse\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def HTMLText(url):\n",
    "    '''\n",
    "    input : text\n",
    "    output : text\n",
    "    outline : urlのwebページにアクセスし、webページのテキストデータを取得する\n",
    "    '''\n",
    "    html = urlopen(url)\n",
    "    \n",
    "    # 結果を出力する\n",
    "    return BeautifulSoup(html.read(), 'html.parser')\n",
    "\n",
    "def GetUrlText(hostName, parameter):\n",
    "    '''\n",
    "    '''\n",
    "    return hostName + parse.quote(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostName = 'https://ja.wikipedia.org/wiki/'\n",
    "targetNames = ['洗剤', 'ウィキペディア', '日本語', 'マスク', 'スプレー', '本', '会社', 'パソコン', '鞄', '生物']\n",
    "\n",
    "for targetName in targetNames:\n",
    "    bs = HTMLText(GetUrlText(hostName, targetName))\n",
    "    text = re.sub(r'\\n+', '\\n', bs.find('div', {'class':'mw-parser-output'}).get_text())\n",
    "    textFileName = 'txt\\{0}.txt'.format(targetName)\n",
    "    textFile = open(textFileName, mode='w', encoding='utf-8')\n",
    "    \n",
    "    for line in re.split(r'\\n', text):\n",
    "        textFile.write(line+'\\n')\n",
    "    textFile.close()\n",
    "    \n",
    "print('テキストファイルを作成しました。テキストファイル名: {0}'.format(', '.join(targetNames))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairList = [[argWord, argClass] for (argWord, argClass) in zip(SplitWord(text), SplitClass(text))]\n",
    "# print(pairList[:5])\n",
    "# \n",
    "# classes = set()\n",
    "# targets = set()\n",
    "# \n",
    "# for item in [pair[1] for pair in pairList]:\n",
    "#     classes.add(item)\n",
    "# print(classes)\n",
    "# \n",
    "# for item in [pair[0] for pair in pairList if pair[1] == '副詞']:\n",
    "#     targets.add(item)\n",
    "# print(targets)\n",
    "# \n",
    "# for sentence in re.split(r'。', text):\n",
    "#     print(sentence + '。')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
